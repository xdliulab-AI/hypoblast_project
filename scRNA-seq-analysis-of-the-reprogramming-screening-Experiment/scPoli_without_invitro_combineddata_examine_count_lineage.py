import os
import argparse
import anndata as ad
import numpy as np
import scanpy as sc
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import scvi
from sklearn.metrics import classification_report
from scarches.models.scpoli import scPoli
from scarches.dataset.trvae.data_handling import remove_sparsity

import warnings
warnings.filterwarnings('ignore')

class scPoliIntegration:
    def __init__(self, seed=42, cell_type_key="lineage_pred", n_top_genes=2000, model_dir=None):
        """åˆå§‹åŒ–scPoliæ•´åˆåˆ†æç±»"""
        self.seed = seed
        self.cell_type_key = cell_type_key
        self.n_top_genes = n_top_genes
        self.model_dir = model_dir
        self.setup_environment()

    def setup_environment(self):
        """è®¾ç½®ç»˜å›¾å’Œè®¡ç®—ç¯å¢ƒ"""
        sc.settings.set_figure_params(dpi=100, frameon=False, figsize=(4, 4))
        plt.rcParams['figure.dpi'] = 100
        plt.rcParams['figure.figsize'] = (4, 4)
        sc.settings.seed = self.seed
        print(f"ç¯å¢ƒè®¾ç½®å®Œæˆ - ç»†èƒç±»å‹é”®: {self.cell_type_key}, é«˜å˜åŸºå› æ•°: {self.n_top_genes}")

    def setup_model_directory(self):
        """è®¾ç½®æ¨¡å‹ä¿å­˜ç›®å½•"""
        if self.model_dir is None:
            # é»˜è®¤ä¿å­˜åˆ°å½“å‰ç›®å½•ä¸‹çš„modelæ–‡ä»¶å¤¹
            self.model_dir = os.path.join(os.getcwd(), "scpoli_model")

        # åˆ›å»ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        os.makedirs(self.model_dir, exist_ok=True)
        print(f"æ¨¡å‹å°†ä¿å­˜åˆ°: {self.model_dir}")
        return self.model_dir

    def check_data_quality(self, adata, dataset_name=""):
        """
        æ£€æŸ¥æ•°æ®è´¨é‡
        """
        print(f"\n=== æ£€æŸ¥ {dataset_name} æ•°æ®è´¨é‡ ===")
        print(f"æ•°æ®ç»´åº¦: {adata.n_obs} ç»†èƒ, {adata.n_vars} åŸºå› ")
        print(f"XçŸ©é˜µç±»å‹: {type(adata.X)}")
        print(f"XçŸ©é˜µæ•°æ®ç±»å‹: {adata.X.dtype}")

        # æ£€æŸ¥ç¨€ç–çŸ©é˜µ
        if hasattr(adata.X, 'toarray'):
            print("XçŸ©é˜µæ˜¯ç¨€ç–çŸ©é˜µ")
            sample_data = adata.X[:5, :5].toarray()
        else:
            sample_data = adata.X[:5, :5]
            print("XçŸ©é˜µæ˜¯ç¨ å¯†çŸ©é˜µ")

        print(f"æ•°æ®æ ·æœ¬ (å‰5x5):\n{sample_data}")

        # æ£€æŸ¥å…³é”®åˆ—æ˜¯å¦å­˜åœ¨
        required_columns = ['orig.ident', self.cell_type_key]
        for col in required_columns:
            if col in adata.obs.columns:
                print(f"{col} å­˜åœ¨ï¼Œå”¯ä¸€å€¼æ•°é‡: {adata.obs[col].nunique()}")
            else:
                print(f"âŒ è­¦å‘Š: {col} ä¸å­˜åœ¨äºæ•°æ®ä¸­")

    def ensure_numeric_data(self, adata):
        """
        ç¡®ä¿æ•°æ®æ˜¯æ•°å€¼ç±»å‹
        """
        print("ç¡®ä¿æ•°æ®ä¸ºæ•°å€¼ç±»å‹...")

        # å¤„ç†XçŸ©é˜µ
        if hasattr(adata.X, 'toarray'):
            # ç¨€ç–çŸ©é˜µè½¬ç¨ å¯†å¹¶ç¡®ä¿float32
            adata.X = adata.X.toarray().astype(np.float32)
        else:
            # ç¡®ä¿æ˜¯float32
            adata.X = adata.X.astype(np.float32)

        print(f"XçŸ©é˜µæ•°æ®ç±»å‹å·²è®¾ç½®ä¸º: {adata.X.dtype}")

        # å¤„ç†layersä¸­çš„counts
        if "counts" in adata.layers:
            if hasattr(adata.layers["counts"], 'toarray'):
                adata.layers["counts"] = adata.layers["counts"].toarray().astype(np.int32)
            else:
                adata.layers["counts"] = adata.layers["counts"].astype(np.int32)
            print(f"countså±‚æ•°æ®ç±»å‹: {adata.layers['counts'].dtype}")

        return adata

    def fix_duplicate_index(self, adata, dataset_name=""):
        """ä¿®å¤é‡å¤çš„ç´¢å¼•"""
        print(f"æ£€æŸ¥ {dataset_name} çš„ç´¢å¼•å”¯ä¸€æ€§...")

        if adata.obs.index.duplicated().any():
            duplicate_count = adata.obs.index.duplicated().sum()
            print(f"å‘ç° {duplicate_count} ä¸ªé‡å¤ç´¢å¼•ï¼Œæ­£åœ¨ä¿®å¤...")

            new_index = []
            count_dict = {}

            for original_idx in adata.obs.index:
                if original_idx not in count_dict:
                    count_dict[original_idx] = 0
                    new_index.append(original_idx)
                else:
                    count_dict[original_idx] += 1
                    new_index.append(f"{original_idx}_dup{count_dict[original_idx]}")

            adata.obs.index = new_index
            print("é‡å¤ç´¢å¼•ä¿®å¤å®Œæˆ")
        else:
            print(f"{dataset_name} ç´¢å¼•å”¯ä¸€æ€§æ£€æŸ¥é€šè¿‡")

        return adata

    def clean_data_types(self, adata):
        """æ¸…ç†æ•°æ®ç±»å‹"""
        print("æ¸…ç†æ•°æ®ç±»å‹...")

        # å®šä¹‰æ•°å€¼åˆ—
        numeric_columns = ['nCount_RNA', 'nFeature_RNA', 'percent.mt']

        for col in numeric_columns:
            if col in adata.obs.columns:
                print(f"å¤„ç†åˆ—: {col}")
                print(f"  åŸå§‹ç±»å‹: {adata.obs[col].dtype}")

                if adata.obs[col].dtype == 'object':
                    try:
                        adata.obs[col] = pd.to_numeric(adata.obs[col], errors='coerce')
                        print(f"  è½¬æ¢ä¸ºæ•°å€¼ç±»å‹: {adata.obs[col].dtype}")
                    except Exception as e:
                        print(f"  è½¬æ¢å¤±è´¥: {e}")
                        adata.obs.drop(columns=[col], inplace=True)

        # ç¡®ä¿åˆ†ç±»å˜é‡æ˜¯å­—ç¬¦ä¸²ç±»å‹
        categorical_columns = ['orig.ident', self.cell_type_key]
        for col in categorical_columns:
            if col in adata.obs.columns:
                adata.obs[col] = adata.obs[col].astype(str)
                print(f"  å°† {col} è½¬æ¢ä¸ºå­—ç¬¦ä¸²ç±»å‹")

        return adata

    def load_and_validate_data(self, data_path):
        """åŠ è½½å’ŒéªŒè¯æ•°æ®"""
        print("åŠ è½½æ•°æ®...")

        # åŠ è½½ä¸»è¦æ•°æ®
        print(f"åŠ è½½ä¸»è¦æ•°æ®: {data_path}")
        adata = sc.read_h5ad(data_path)
        print(f"ä¸»è¦æ•°æ®ç»´åº¦: {adata.n_obs} ç»†èƒ, {adata.n_vars} åŸºå› ")

        # æ£€æŸ¥æ•°æ®è´¨é‡
        self.check_data_quality(adata, "ä¸»è¦æ•°æ®")

        # ä¿®å¤é‡å¤ç´¢å¼•
        adata = self.fix_duplicate_index(adata, "ä¸»è¦æ•°æ®")

        # æ¸…ç†æ•°æ®ç±»å‹
        adata = self.clean_data_types(adata)

        # ç¡®ä¿æ•°å€¼æ•°æ®
        adata = self.ensure_numeric_data(adata)

        return adata

    def preprocess_data(self, adata):
        """æ•°æ®é¢„å¤„ç†"""
        print("æ•°æ®é¢„å¤„ç†...")

        # ç¡®ä¿æ¨¡å‹ç›®å½•å·²è®¾ç½®
        self.setup_model_directory()

        # ä½¿ç”¨ä¸´æ—¶å‰¯æœ¬è¿›è¡Œé«˜å˜åŸºå› é€‰æ‹©
        print("ä½¿ç”¨ä¸´æ—¶å‰¯æœ¬è¿›è¡Œé«˜å˜åŸºå› é€‰æ‹©...")
        adata_tmp = adata.copy()

        # ç¡®ä¿ä¸´æ—¶æ•°æ®æ˜¯æ•°å€¼ç±»å‹
        adata_tmp = self.ensure_numeric_data(adata_tmp)

        # å¯¹ä¸´æ—¶æ•°æ®è¿›è¡Œæ ‡å‡†åŒ–å’Œlogè½¬æ¢
        print("å¯¹ä¸´æ—¶æ•°æ®è¿›è¡Œæ ‡å‡†åŒ–...")
        sc.pp.normalize_total(adata_tmp, target_sum=1e4)
        sc.pp.log1p(adata_tmp)

        # é€‰æ‹©é«˜å˜åŸºå› 
        print("é€‰æ‹©é«˜å˜åŸºå› ...")
        sc.pp.highly_variable_genes(
            adata_tmp,
            n_top_genes=self.n_top_genes,
            flavor="cell_ranger",
            batch_key="orig.ident",
            subset=False
        )

        # ä½¿ç”¨é«˜å˜åŸºå› ç­›é€‰åŸå§‹æ•°æ®
        print(f"ä½¿ç”¨ {self.n_top_genes} ä¸ªé«˜å˜åŸºå› ç­›é€‰æ•°æ®...")
        hvg_mask = adata_tmp.var['highly_variable'].values
        adata_hvg = adata[:, hvg_mask].copy()

        # å°†é«˜å˜åŸºå› ä¿¡æ¯æ·»åŠ åˆ°åŸå§‹æ•°æ®
        adata.var['highly_variable'] = hvg_mask

        # å‡†å¤‡ç”¨äºscPoliè®­ç»ƒçš„æ•°æ®
        print("å‡†å¤‡scPoliè®­ç»ƒæ•°æ®...")

        # ç¡®ä¿æ•°æ®æ˜¯æµ®ç‚¹æ•°ç±»å‹
        adata_hvg = self.ensure_numeric_data(adata_hvg)

        # ç¡®ä¿countså±‚å­˜åœ¨ä¸”ä¸ºæ•´æ•°
        if "counts" not in adata_hvg.layers:
            # åˆ›å»ºcountså±‚ï¼ˆå‡è®¾XçŸ©é˜µåŒ…å«åŸå§‹countsï¼‰
            if np.issubdtype(adata_hvg.X.dtype, np.floating):
                # å¦‚æœæ˜¯æµ®ç‚¹æ•°ï¼Œè½¬æ¢ä¸ºæ•´æ•°ï¼ˆå››èˆäº”å…¥ï¼‰
                counts_data = np.round(adata_hvg.X).astype(np.int32)
            else:
                counts_data = adata_hvg.X.astype(np.int32)
            adata_hvg.layers["counts"] = counts_data
            print("åˆ›å»ºäº†countså±‚")
        else:
            # ç¡®ä¿countså±‚æ˜¯æ•´æ•°ç±»å‹
            if hasattr(adata_hvg.layers["counts"], 'toarray'):
                counts_data = adata_hvg.layers["counts"].toarray().astype(np.int32)
            else:
                counts_data = adata_hvg.layers["counts"].astype(np.int32)
            adata_hvg.layers["counts"] = counts_data

        print(f"é«˜å˜åŸºå› æ•°æ®ç»´åº¦: {adata_hvg.shape}")
        print(f"é«˜å˜åŸºå› æ•°é‡: {adata_hvg.n_vars}")
        print(f"XçŸ©é˜µæ•°æ®ç±»å‹: {adata_hvg.X.dtype}")
        print(f"countså±‚æ•°æ®ç±»å‹: {adata_hvg.layers['counts'].dtype}")

        return adata_hvg

    def train_scpoli_model(self, adata):
        """è®­ç»ƒscPoliæ¨¡å‹"""
        # è®¾ç½®æ¨¡å‹ç›®å½•
        model_dir = self.setup_model_directory()
        model_subdir = os.path.join(model_dir, f'scpoli_model_{self.cell_type_key}_hvg{self.n_top_genes}')

        print("\n=== scPoli æ¨¡å‹è®­ç»ƒ ===")

        # æ•°æ®éªŒè¯
        print("éªŒè¯è®­ç»ƒæ•°æ®...")
        print(f"æ•°æ®å½¢çŠ¶: {adata.shape}")
        print(f"XçŸ©é˜µæ•°æ®ç±»å‹: {adata.X.dtype}")

        # æ£€æŸ¥æ•°æ®èŒƒå›´
        if hasattr(adata.X, 'toarray'):
            x_data = adata.X.toarray()
        else:
            x_data = adata.X

        print(f"æ•°æ®èŒƒå›´: [{x_data.min():.2f}, {x_data.max():.2f}]")
        print(f"æ•°æ®å‡å€¼: {x_data.mean():.2f}")

        # è®¾ç½®å‚æ•°
        condition_key = "orig.ident"
        cell_type_key = self.cell_type_key

        print(f"æ¡ä»¶å˜é‡: {condition_key}")
        print(f"ç»†èƒç±»å‹å˜é‡: {cell_type_key}")
        print(f"æ¡ä»¶åˆ†å¸ƒ:\n{adata.obs[condition_key].value_counts()}")
        print(f"ç»†èƒç±»å‹åˆ†å¸ƒ:\n{adata.obs[cell_type_key].value_counts()}")

        # ç¡®ä¿åˆ†ç±»å˜é‡æ˜¯å­—ç¬¦ä¸²ç±»å‹
        adata.obs[condition_key] = adata.obs[condition_key].astype(str)
        adata.obs[cell_type_key] = adata.obs[cell_type_key].astype(str)

        # è®­ç»ƒå‚æ•°
        early_stopping_kwargs = {
            "early_stopping_metric": "val_prototype_loss",
            "mode": "min",
            "threshold": 0,
            "patience": 20,
            "reduce_lr": True,
            "lr_patience": 13,
            "lr_factor": 0.1,
        }

        # è®­ç»ƒscPoliæ¨¡å‹
        print("åˆå§‹åŒ–scPoliæ¨¡å‹...")

        try:
            scpoli_model = scPoli(
                adata=adata,
                condition_keys=condition_key,
                cell_type_keys=cell_type_key,
                embedding_dims=50,
                recon_loss='nb'
            )

            print("å¼€å§‹è®­ç»ƒscPoliæ¨¡å‹...")
            scpoli_model.train(
                n_epochs=50,
                pretraining_epochs=40,
                early_stopping_kwargs=early_stopping_kwargs,
                eta=5
            )

            print("âœ… scPoliæ¨¡å‹è®­ç»ƒå®Œæˆ")

        except Exception as e:
            print(f"âŒ scPoliæ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
            raise

        return scpoli_model, model_subdir

    def save_model_and_results(self, scpoli_model, model_dir, adata):
        """ä¿å­˜æ¨¡å‹å’Œç»“æœ"""
        print("ä¿å­˜æ¨¡å‹å’Œç»“æœ...")

        # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
        adata = self.clean_data_types(adata)
        adata = self.ensure_numeric_data(adata)

        # ä¿å­˜æ¨¡å‹
        try:
            print(f"ä¿å­˜æ¨¡å‹åˆ°: {model_dir}")
            scpoli_model.save(model_dir, overwrite=True, save_anndata=True)
            print(f"âœ… æ¨¡å‹å·²ä¿å­˜è‡³ {model_dir}")
        except Exception as e:
            print(f"âŒ ä¿å­˜é”™è¯¯: {e}")
            # å°è¯•å…¶ä»–ä¿å­˜æ–¹å¼
            try:
                import pickle
                model_path = os.path.join(model_dir, "scpoli_model.pkl")
                with open(model_path, 'wb') as f:
                    pickle.dump(scpoli_model, f)
                print(f"âœ… æ¨¡å‹å·²é€šè¿‡pickleä¿å­˜è‡³ {model_path}")
            except Exception as e2:
                print(f"âŒ pickleä¿å­˜ä¹Ÿå¤±è´¥: {e2}")

        return scpoli_model

    def get_latent_representation(self, scpoli_model, adata):
        """è·å–æ½œåœ¨è¡¨ç¤º"""
        print("è·å–scPoliæ½œåœ¨è¡¨ç¤º...")

        try:
            scpoli_model.model.eval()

            # ç¡®ä¿æ•°æ®æ ¼å¼æ­£ç¡®
            if hasattr(adata.X, 'toarray'):
                adata.X = adata.X.toarray().astype(np.float32)

            data_latent_source = scpoli_model.get_latent(adata, mean=True)
            adata.obsm["scPoli"] = data_latent_source

            print(f"æ½œåœ¨è¡¨ç¤ºç»´åº¦: {data_latent_source.shape}")
            print("âœ… æ½œåœ¨è¡¨ç¤ºè·å–æˆåŠŸ")

        except Exception as e:
            print(f"âŒ è·å–æ½œåœ¨è¡¨ç¤ºå¤±è´¥: {e}")
            raise

        return adata

    def perform_clustering_analysis(self, adata):
        """æ‰§è¡Œé™ç»´èšç±»åˆ†æ"""
        print("æ‰§è¡Œé™ç»´èšç±»åˆ†æ...")
        
        # è®¡ç®—é‚»å±…å›¾
        print("è®¡ç®—é‚»å±…å›¾...")
        sc.pp.neighbors(adata, use_rep="scPoli", random_state=self.seed)
        
        # UMAPé™ç»´
        print("è®¡ç®—UMAP...")
        sc.tl.umap(adata, random_state=self.seed)
        
        # Leidenèšç±»
        print("æ‰§è¡ŒLeidenèšç±»...")
        sc.tl.leiden(adata, random_state=self.seed)
        
        # å¯é€‰ï¼šå°è¯•ä¸åŒçš„åˆ†è¾¨ç‡å‚æ•°è¿›è¡Œèšç±»
        print("å°è¯•ä¸åŒçš„èšç±»åˆ†è¾¨ç‡...")
        for res in [0.4, 0.6, 0.8, 1.0]:
            cluster_key = f'leiden_res_{res}'
            sc.tl.leiden(adata, resolution=res, key_added=cluster_key, random_state=self.seed)
            print(f"  {cluster_key}: {adata.obs[cluster_key].nunique()} ä¸ªèšç±»")
        
        print("âœ… é™ç»´èšç±»åˆ†æå®Œæˆ")
        return adata

    def save_integrated_data(self, adata):
        """ä¿å­˜æ•´åˆåçš„æ•°æ®ï¼ˆåŒ…å«æ‰€æœ‰èšç±»ç»“æœï¼‰"""
        print("ä¿å­˜æ•´åˆåçš„æ•°æ®...")
        
        # ç¡®ä¿æ¨¡å‹ç›®å½•å·²è®¾ç½®
        self.setup_model_directory()
        
        # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
        adata = self.clean_data_types(adata)
        adata = self.ensure_numeric_data(adata)
        
        # æ„å»ºè¾“å‡ºè·¯å¾„
        output_path = os.path.join(self.model_dir, f"scpoli_integrated_{self.cell_type_key}_hvg{self.n_top_genes}.h5ad")
        
        try:
            # ä¿å­˜åŒ…å«æ‰€æœ‰åˆ†æç»“æœçš„h5adæ–‡ä»¶
            adata.write_h5ad(output_path)
            print(f"âœ… æ•´åˆæ•°æ®å·²ä¿å­˜è‡³: {output_path}")
            print(f"   åŒ…å«ä»¥ä¸‹åˆ†æç»“æœ:")
            print(f"   - æ½œåœ¨è¡¨ç¤º (scPoli): {adata.obsm['scPoli'].shape}")
            print(f"   - UMAPåæ ‡: {adata.obsm['X_umap'].shape}")
            print(f"   - Leidenèšç±»ç»“æœ: {list(adata.obs.columns[adata.obs.columns.str.startswith('leiden')])}")
            
        except Exception as e:
            print(f"âŒ ä¿å­˜æ•´åˆæ•°æ®æ—¶å‡ºé”™: {e}")
            # å°è¯•ä¿å­˜åˆ°å½“å‰ç›®å½•
            fallback_path = f'scpoli_integrated_{self.cell_type_key}_hvg{self.n_top_genes}.h5ad'
            try:
                adata.write_h5ad(fallback_path)
                print(f"âœ… æ•´åˆæ•°æ®å·²ä¿å­˜åˆ°å½“å‰ç›®å½•: {fallback_path}")
            except Exception as e2:
                print(f"âŒ æ•´åˆæ•°æ®ä¿å­˜å¤±è´¥: {e2}")
        
        return output_path

    def visualize_results(self, adata):
        """å¯è§†åŒ–ç»“æœ"""
        print("åŸºäºscPoliçš„èšç±»å¯è§†åŒ–...")

        # ç¡®ä¿æ¨¡å‹ç›®å½•å·²è®¾ç½®
        self.setup_model_directory()

        # ç»˜åˆ¶UMAPå›¾ - orig.ident
        plt.figure(figsize=(8, 6))
        sc.pl.umap(adata, color="orig.ident", frameon=False, show=False,
                  title=f"Batch (orig.ident) - {self.n_top_genes} HVGs", size=20)
        plt.tight_layout()
        plot_path = os.path.join(self.model_dir, f"scpoli_orig_ident_{self.cell_type_key}_hvg{self.n_top_genes}.pdf")
        plt.savefig(plot_path, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"âœ… æ‰¹æ¬¡UMAPå›¾ä¿å­˜è‡³: {plot_path}")

        # ç»˜åˆ¶UMAPå›¾ - lineage_pred
        plt.figure(figsize=(8, 6))
        sc.pl.umap(adata, color=self.cell_type_key, frameon=False, show=False,
                  title=f"Cell Type ({self.cell_type_key}) - {self.n_top_genes} HVGs", size=20)
        plt.tight_layout()
        plot_path = os.path.join(self.model_dir, f"scpoli_{self.cell_type_key}_hvg{self.n_top_genes}.pdf")
        plt.savefig(plot_path, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"âœ… ç»†èƒç±»å‹UMAPå›¾ä¿å­˜è‡³: {plot_path}")

        # ç»˜åˆ¶UMAPå›¾ - leidenèšç±» (é»˜è®¤åˆ†è¾¨ç‡)
        plt.figure(figsize=(8, 6))
        sc.pl.umap(adata, color="leiden", frameon=False, show=False,
                  title=f"Leiden Clusters - {self.n_top_genes} HVGs", size=20)
        plt.tight_layout()
        plot_path = os.path.join(self.model_dir, f"scpoli_leiden_{self.cell_type_key}_hvg{self.n_top_genes}.pdf")
        plt.savefig(plot_path, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"âœ… Leidenèšç±»UMAPå›¾ä¿å­˜è‡³: {plot_path}")

        # ç»˜åˆ¶ä¸åŒåˆ†è¾¨ç‡çš„èšç±»ç»“æœ
        leiden_cols = [col for col in adata.obs.columns if col.startswith('leiden_res_')]
        for col in leiden_cols:
            plt.figure(figsize=(8, 6))
            sc.pl.umap(adata, color=col, frameon=False, show=False,
                      title=f"Leiden {col} - {self.n_top_genes} HVGs", size=20)
            plt.tight_layout()
            plot_path = os.path.join(self.model_dir, f"scpoli_{col}_{self.cell_type_key}_hvg{self.n_top_genes}.pdf")
            plt.savefig(plot_path, dpi=300, bbox_inches='tight')
            plt.close()
            print(f"âœ… {col} UMAPå›¾ä¿å­˜è‡³: {plot_path}")

    def run_full_analysis(self, data_path):
        """è¿è¡Œå®Œæ•´åˆ†ææµç¨‹"""
        try:
            print("=== å¼€å§‹å®Œæ•´scPoliåˆ†ææµç¨‹ ===")

            # 1. åŠ è½½æ•°æ®
            print("\næ­¥éª¤1: åŠ è½½å’ŒéªŒè¯æ•°æ®")
            adata = self.load_and_validate_data(data_path)

            # 2. æ•°æ®é¢„å¤„ç†
            print("\næ­¥éª¤2: æ•°æ®é¢„å¤„ç†")
            adata_hvg = self.preprocess_data(adata)

            # 3. è®­ç»ƒscPoliæ¨¡å‹
            print("\næ­¥éª¤3: è®­ç»ƒscPoliæ¨¡å‹")
            scpoli_model, model_dir = self.train_scpoli_model(adata_hvg)

            # 4. ä¿å­˜æ¨¡å‹
            print("\næ­¥éª¤4: ä¿å­˜æ¨¡å‹")
            scpoli_model = self.save_model_and_results(scpoli_model, model_dir, adata_hvg)

            # 5. è·å–æ½œåœ¨è¡¨ç¤º
            print("\næ­¥éª¤5: è·å–æ½œåœ¨è¡¨ç¤º")
            adata = self.get_latent_representation(scpoli_model, adata_hvg)

            # 6. æ‰§è¡Œé™ç»´èšç±»åˆ†æ
            print("\næ­¥éª¤6: æ‰§è¡Œé™ç»´èšç±»åˆ†æ")
            adata = self.perform_clustering_analysis(adata)

            # 7. ä¿å­˜æ•´åˆåçš„æ•°æ®ï¼ˆåŒ…å«æ‰€æœ‰èšç±»ç»“æœï¼‰
            print("\næ­¥éª¤7: ä¿å­˜æ•´åˆæ•°æ®")
            output_path = self.save_integrated_data(adata)

            # 8. å¯è§†åŒ–ç»“æœ
            print("\næ­¥éª¤8: å¯è§†åŒ–ç»“æœ")
            self.visualize_results(adata)

            print("\nğŸ‰ âœ… scPoliåˆ†æå®Œæˆï¼")
            print(f"æ¨¡å‹å’Œç»“æœä¿å­˜åœ¨: {self.model_dir}")
            print(f"æœ€ç»ˆh5adæ–‡ä»¶åŒ…å«:")
            print(f"  - scPoliæ½œåœ¨è¡¨ç¤º")
            print(f"  - UMAPé™ç»´åæ ‡") 
            print(f"  - Leidenèšç±»ç»“æœï¼ˆå¤šç§åˆ†è¾¨ç‡ï¼‰")
            print(f"  - æ‰€æœ‰åŸå§‹è§‚æµ‹æ•°æ®å’Œå˜é‡æ•°æ®")
            print(f"æ–‡ä»¶ä½ç½®: {output_path}")

        except Exception as e:
            print(f"\nâŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            import traceback
            print(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯:\n{traceback.format_exc()}")
            raise


def main():
    """ä¸»å‡½æ•°ï¼Œæ”¯æŒå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='scPoliæ•´åˆåˆ†æ - ä¸“æ³¨äºlineage_predç»†èƒç±»å‹')
    parser.add_argument('--data_path', type=str, required=True,
                       help='è¾“å…¥æ•°æ®è·¯å¾„ (H5ADæ ¼å¼ï¼Œå¿…éœ€)')
    parser.add_argument('--n_top_genes', type=int, choices=[2000, 4000],
                       default=2000, help='é«˜å˜åŸºå› æ•°é‡: 2000 æˆ– 4000 (é»˜è®¤: 2000)')
    parser.add_argument('--seed', type=int, default=42, help='éšæœºç§å­ (é»˜è®¤: 42)')
    parser.add_argument('--model_dir', type=str, default=None,
                       help='æ¨¡å‹ä¿å­˜ç›®å½• (é»˜è®¤: å½“å‰ç›®å½•ä¸‹çš„scpoli_modelæ–‡ä»¶å¤¹)')

    args = parser.parse_args()

    print("=" * 60)
    print("scPoliæ•´åˆåˆ†æ - lineage_predç»†èƒç±»å‹")
    print("=" * 60)
    print(f"æ•°æ®è·¯å¾„: {args.data_path}")
    print(f"ç»†èƒç±»å‹é”®: lineage_pred")
    print(f"é«˜å˜åŸºå› æ•°: {args.n_top_genes}")
    print(f"éšæœºç§å­: {args.seed}")
    print(f"æ¨¡å‹ç›®å½•: {args.model_dir if args.model_dir else 'å½“å‰ç›®å½•ä¸‹çš„scpoli_modelæ–‡ä»¶å¤¹'}")
    print("=" * 60)

    # éªŒè¯æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.data_path):
        print(f"âŒ é”™è¯¯: æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {args.data_path}")
        return

    # åˆ›å»ºåˆ†æå™¨å®ä¾‹
    analyzer = scPoliIntegration(
        seed=args.seed,
        cell_type_key="lineage_pred",  # å›ºå®šä½¿ç”¨lineage_pred
        n_top_genes=args.n_top_genes,
        model_dir=args.model_dir
    )

    # è¿è¡Œåˆ†æ
    analyzer.run_full_analysis(args.data_path)


# è¿è¡Œåˆ†æ
if __name__ == "__main__":
    main()
